{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "aef673f4",
      "metadata": {
        "id": "aef673f4"
      },
      "source": [
        "# **Despliege del Modelo con MLFlow**\n",
        "---\n",
        "\n",
        "En este notebook se desplegará el modelo utilizando la API de `mlflow` a través de la librería `requests`.\n",
        "\n",
        "Comenzamos configurando el servidor de `mlflow` e importando las librerías necesarias:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91ae66d7",
      "metadata": {
        "id": "91ae66d7"
      },
      "outputs": [],
      "source": [
        "!pip install mlflow requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6419d6ef",
      "metadata": {
        "id": "6419d6ef"
      },
      "outputs": [],
      "source": [
        "import mlflow\n",
        "import os\n",
        "import logging\n",
        "import pandas as pd\n",
        "from IPython.display import display"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb0fee0c",
      "metadata": {
        "id": "fb0fee0c"
      },
      "source": [
        "Adicionalmente, utilizaremos un servidor de `mlflow`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d8af5ff",
      "metadata": {
        "id": "9d8af5ff"
      },
      "outputs": [],
      "source": [
        "command = \"\"\"\n",
        "mlflow server \\\n",
        "        --backend-store-uri sqlite:///tracking.db \\\n",
        "        --default-artifact-root file:mlruns \\\n",
        "        -p 5000 &\n",
        "\"\"\"\n",
        "get_ipython().system_raw(command)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65b101c3",
      "metadata": {
        "id": "65b101c3"
      },
      "source": [
        "Utilizaremos `ngrok` para acceder al tablero de `mlflow`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cafa2dbc",
      "metadata": {
        "id": "cafa2dbc"
      },
      "outputs": [],
      "source": [
        "!pip install pyngrok"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf1b4c84",
      "metadata": {
        "id": "bf1b4c84"
      },
      "source": [
        "Ahora debe agregar su token de `ngrok`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e0f6138",
      "metadata": {
        "id": "0e0f6138"
      },
      "outputs": [],
      "source": [
        "token = \"2pEXurcBWiJur3b8zAfzNp2YbbE_82H8edeFMVSNbouejjwva\" # Agregue el token dentro de las comillas\n",
        "os.environ[\"NGROK_TOKEN\"] = token"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62a74048",
      "metadata": {
        "id": "62a74048"
      },
      "source": [
        "Nos autenticamos en ngrok:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "075cced6",
      "metadata": {
        "id": "075cced6"
      },
      "outputs": [],
      "source": [
        "!ngrok authtoken $NGROK_TOKEN"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c43ace2d",
      "metadata": {
        "id": "c43ace2d"
      },
      "source": [
        "Ahora, lanzamos la conexión con ngrok:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61148bc9",
      "metadata": {
        "id": "61148bc9"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "ngrok.connect(5000, \"http\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1bc8d9ff",
      "metadata": {
        "id": "1bc8d9ff"
      },
      "source": [
        "Especificamos que MLFlow debe usar el servidor que estamos manejando."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abba2577",
      "metadata": {
        "id": "abba2577"
      },
      "outputs": [],
      "source": [
        "mlflow.set_tracking_uri(\"http://localhost:5000\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e731d9f1",
      "metadata": {
        "id": "e731d9f1"
      },
      "source": [
        "Vamos a crear un experimento en MLFlow para este conjunto de datos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1319c8b5",
      "metadata": {
        "id": "1319c8b5"
      },
      "outputs": [],
      "source": [
        "exp_id = mlflow.create_experiment(name=\"DiaBoost\", artifact_location=\"mlruns/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc50d0f2",
      "metadata": {
        "id": "dc50d0f2"
      },
      "source": [
        "## **1. Carga de Datos**\n",
        "---\n",
        "\n",
        "Este conjunto de datos es una colección de datos médicos y demográficos de pacientes, junto con una etiqueta que indica si el paciente tiene o no diabetes. Los datos incluyen características como la edad, el sexo, el índice de masa corporal (IMC), la hipertensión, las cardiopatías, el historial de tabaquismo, el nivel de HbA1c y el nivel de glucosa en sangre.\n",
        "\n",
        "El entrenamiento de un modelo de Machine Learning con estos datos puede ser útil para que los profesionales sanitarios identifiquen a los pacientes que pueden estar en riesgo de desarrollar diabetes y desarrollen planes de tratamiento personalizados. Además, el conjunto de datos puede ser utilizado por los investigadores para explorar las relaciones entre diversos factores médicos y demográficos y la probabilidad de desarrollar diabetes.\n",
        "\n",
        "Estos datos provienen originalmente de [Electronic Health Records (EHRs)](https://www.cms.gov/priorities/key-initiatives/e-health/records); de allí fueron tomados, agrupados, procesados y republicados en [Kaggle](https://www.kaggle.com/datasets/iammustafatz/diabetes-prediction-dataset).\n",
        "\n",
        "Vamos a cargar este conjunto de datos:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_logger():\n",
        "  logging.basicConfig(level = logging.INFO, format = '%(asctime)s - %(levenname)s - %(message)s')\n",
        "  logger = logging.getLogger('Logger')\n",
        "  logger.info('Logger creado')\n",
        "  return logger\n",
        "\n",
        "\n",
        "def download_firebase(url, logger):\n",
        "  logger.info(\"Extrayendo el archivo desde Firebase\")\n",
        "  df = None\n",
        "  try:\n",
        "    df = pd.read_csv(url)\n",
        "    logger.info(\"Archivo cargado\")\n",
        "  except requests.exceptions.RequestException as e:\n",
        "    logger.info(f\"Error al descargar el archivo CSV: {e}\")\n",
        "  except pd.errors.EmptyDataError:\n",
        "    logger.info(\"El archivo CSV está vacío.\")\n",
        "  except Exception as e:\n",
        "    logger.info(f\"Ocurrió un error inesperado: {e}\")\n",
        "  return df"
      ],
      "metadata": {
        "id": "0zolIQhEY7mE"
      },
      "id": "0zolIQhEY7mE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db5b8e69",
      "metadata": {
        "id": "db5b8e69"
      },
      "outputs": [],
      "source": [
        "# Cargar DataSet\n",
        "url = 'https://firebasestorage.googleapis.com/v0/b/personalwp-8822c.appspot.com/o/diabetes_prediction_dataset.csv?alt=media&token=4d70d154-c3d0-4fa0-a3aa-9b9972dd3b95'\n",
        "logger = create_logger()\n",
        "data = download_firebase(url,logger)\n",
        "display(data.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e4e167b",
      "metadata": {
        "id": "1e4e167b"
      },
      "source": [
        "Este conjunto de datos tiene los siguientes campos:\n",
        "\n",
        "| **Variable** | **Descripción** | **Tipo de dato** | **Rango/Valores posibles** |\n",
        "|---|---|---|---|\n",
        "| **gender** | Género del paciente | Categórico (string) | Female, Male, Other |\n",
        "| **age** | Edad del paciente | Numérico (float) | 102 posibles valores entre 0.08 y 80.0 |\n",
        "| **hypertension** | Indica si el paciente tiene hipertensión | Categórico (bool) | 0, 1 (0: No, 1: Sí) |\n",
        "| **heart_disease** | Indica si el paciente tiene una enfermedad cardíaca | Categórico (bool) | 0, 1 (0: No, 1: Sí) |\n",
        "| **smoking_history** | Antecedentes de tabaquismo del paciente | Categórico (string) | never, No Info, current, former, ever, not current |\n",
        "| **bmi** | Índice de masa corporal del paciente | Numérico (float) | 4247 posibles valores entre 10.01 y 95.69 |\n",
        "| **HbA1c_level** | Nivel promedio de glucosa en sangre del paciente (últimos meses) | Numérico (float) | 18 posibles valores entre 3.5 y 9.0 |\n",
        "| **blood_glucose_level** | Nivel de glucosa en sangre del paciente (en el momento de la prueba) | Numérico (int) | 18 posibles valores entre 80 y 300 |\n",
        "| **diabetes** | Indica si el paciente tiene diabetes | Categórico (bool) | 0, 1 (0: No, 1: Sí) |\n",
        "\n",
        "Vamos a preprocesar los datos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "803e7f4e",
      "metadata": {
        "id": "803e7f4e"
      },
      "outputs": [],
      "source": [
        "# Valores atípicos en 'bmi'\n",
        "seventy_fifth = data['bmi'].quantile(0.75)\n",
        "twenty_fifth = data['bmi'].quantile(0.25)\n",
        "iqr = seventy_fifth - twenty_fifth\n",
        "upper = seventy_fifth + (10 * iqr)\n",
        "outliers_bmi_upper = data[(data['bmi'] > upper)]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Eliminación de valores atípicos en 'bmi'\n",
        "data = pd.merge(data, outliers_bmi_upper, indicator = True, how = 'outer').query('_merge == \"left_only\"').drop('_merge', axis = 1)"
      ],
      "metadata": {
        "id": "SOWXyaM3Zs3l"
      },
      "id": "SOWXyaM3Zs3l",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Eliminación de valores duplicados\n",
        "data = data.drop_duplicates(keep = \"first\")"
      ],
      "metadata": {
        "id": "7S3V6xrIZvQN"
      },
      "id": "7S3V6xrIZvQN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Variables Categóricas a Numéricas\n",
        "data['gender'] = pd.factorize(data['gender'])[0]\n",
        "data['smoking_history'] = pd.factorize(data['smoking_history'])[0]"
      ],
      "metadata": {
        "id": "XgsJlAQsayGn"
      },
      "id": "XgsJlAQsayGn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Información del DataSet\n",
        "data.info()"
      ],
      "metadata": {
        "id": "R6Xl9ouhaCbq"
      },
      "id": "R6Xl9ouhaCbq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "ad1915c0",
      "metadata": {
        "id": "ad1915c0"
      },
      "source": [
        "## **2. Modelamiento**\n",
        "---\n",
        "\n",
        "Ahora, veamos el entrenamiento de un modelo de `xgboost`, para escoger los mejores hiperparámetros instalamos `optuna`:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "id": "gNLFH9ZiaiT5"
      },
      "id": "gNLFH9ZiaiT5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9e8151b",
      "metadata": {
        "id": "a9e8151b"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4ec0a3f",
      "metadata": {
        "id": "d4ec0a3f"
      },
      "source": [
        "Dividimos el conjunto de datos en entrenamiento y prueba para validar la generalización del modelo:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separación de la 'Data' (Características)\n",
        "X = data.drop(columns = 'diabetes')\n",
        "X.shape"
      ],
      "metadata": {
        "id": "-Jcc4VFSa9DL"
      },
      "id": "-Jcc4VFSa9DL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separación del 'Target' (Variable objetivo)\n",
        "y = data['diabetes']\n",
        "y.shape"
      ],
      "metadata": {
        "id": "8FOQ8g-lbG0x"
      },
      "id": "8FOQ8g-lbG0x",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b067a690",
      "metadata": {
        "id": "b067a690"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Partición de los datos: 70% para entrenamiento, 30% para prueba y estratificación en las etiquetas (y)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42, stratify = y)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Validación de la partición de los datos\n",
        "print(f'Número de muestras en entrenamiento: {X_train.shape[0]}')\n",
        "print(f'Número de muestras en prueba: {X_test.shape[0]}')\n",
        "print(f'Número de características: {X_train.shape[1]}')"
      ],
      "metadata": {
        "id": "_NOGhy-1bQwk"
      },
      "id": "_NOGhy-1bQwk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# Distribución de la variable objetivo en los conjuntos de entrenamiento y prueba\n",
        "print(f'Distribución de clases en entrenamiento: {np.bincount(y_train)}')\n",
        "print(f'Distribución de clases en prueba: {np.bincount(y_test)}')"
      ],
      "metadata": {
        "id": "0Ts8Jm-cbUTv"
      },
      "id": "0Ts8Jm-cbUTv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "cfd71a1d",
      "metadata": {
        "id": "cfd71a1d"
      },
      "source": [
        "Entrenamos el modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e503d0e",
      "metadata": {
        "id": "1e503d0e"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def objective(trial):\n",
        "  max_depth = trial.suggest_int(\"max_depth\", 1, 100)\n",
        "  n_estimators = trial.suggest_int(\"n_estimators\", 1, 200)\n",
        "  learning_rate = trial.suggest_float(\"learning_rate\", 1e-6, 1, log = True)\n",
        "  model = XGBClassifier(max_depth = max_depth, n_estimators = n_estimators, learning_rate = learning_rate)\n",
        "  model.fit(X_train, y_train)\n",
        "  y_pred = model.predict(X_test)\n",
        "  score = accuracy_score(y_test, y_pred)\n",
        "  return score"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33d98864",
      "metadata": {
        "id": "33d98864"
      },
      "source": [
        "Sobre este modelo, debe generar una versión con el\n",
        "nombre `DiaBoost`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "study = optuna.create_study(direction = \"maximize\", storage = \"sqlite:///hp.db\", study_name = \"DiaBoost\")\n",
        "study.optimize(func = objective, n_trials = 100, n_jobs = -1)"
      ],
      "metadata": {
        "id": "WPAdEEMbdUTT"
      },
      "id": "WPAdEEMbdUTT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mejor hiperparámetro\n",
        "params = study.best_params\n",
        "print(params)"
      ],
      "metadata": {
        "id": "kC6MxR3NeUBV"
      },
      "id": "kC6MxR3NeUBV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mejor metrica\n",
        "score = study.best_value\n",
        "print(score)"
      ],
      "metadata": {
        "id": "zMaOKhEdeYbh"
      },
      "id": "zMaOKhEdeYbh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "6ab10e1c",
      "metadata": {
        "id": "6ab10e1c"
      },
      "source": [
        "## **3. Despliegue** [1]\n",
        "---\n",
        "\n",
        "`mlflow` nos permite desplegar modelos como **REST APIs** de forma muy sencilla. Un REST API (acrónimo en inglés de *Representational State Transfer Application Programming Interface*) es un tipo de API (*Application Programming Interface*) que utiliza la arquitectura REST para proporcionar servicios web. REST es un conjunto de principios y restricciones que se utilizan para crear servicios web escalables y flexibles que pueden ser accedidos desde cualquier dispositivo o plataforma que tenga conexión a Internet.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1zNq0W7kTnw4nCN2hNGEevWXNfa6TKH7E\" width=\"80%\">\n",
        "\n",
        "En un REST API, los datos son transferidos entre el cliente y el servidor a través de solicitudes HTTP estándar, como GET, POST, PUT y DELETE. Estas solicitudes se utilizan para realizar operaciones en los recursos que se encuentran en el servidor. Los recursos se identifican mediante URLs y los datos se transfieren en un formato estandarizado, como JSON o XML.\n",
        "\n",
        "El uso de REST API se ha vuelto muy popular en los últimos años debido a que es un enfoque muy flexible y escalable para construir servicios web. Muchas aplicaciones móviles y web utilizan REST API para acceder a datos y realizar operaciones en ellos.\n",
        "\n",
        "`mlflow` permite desplegar modelos que ya se encuentran en el registro por medio de un REST API sencillo que toma como entrada los datos de un modelo y devuelve las predicciones:\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1glFzD_ngp-QMN8NWfQfjM3sUWJZnvdLY\" width=\"80%\">\n",
        "\n",
        "Para crear el API de `mlflow` debemos especificar la url del servidor de seguimiento de `mlflow`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88bd8d33",
      "metadata": {
        "id": "88bd8d33"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"MLFLOW_TRACKING_URI\"] = \"http://localhost:5000\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e6b1782",
      "metadata": {
        "id": "7e6b1782"
      },
      "source": [
        "Ahora, lanzamos el API con `mlflow`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80af897a",
      "metadata": {
        "id": "80af897a"
      },
      "outputs": [],
      "source": [
        "command = \"\"\"\n",
        "mlflow models serve -m 'models:/DiaBoost/1' -p 8001 --env-manager 'local' &\n",
        "\"\"\"\n",
        "get_ipython().system_raw(command)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7207bd7c",
      "metadata": {
        "id": "7207bd7c"
      },
      "source": [
        "Esto genera un API que está ejecutándose en el puerto `8001`. Veamos cómo podemos enviarle datos con la librería `requests`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "000b46a6",
      "metadata": {
        "id": "000b46a6"
      },
      "outputs": [],
      "source": [
        "import requests"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a219917",
      "metadata": {
        "id": "5a219917"
      },
      "source": [
        "Vamos a enviarle dos registros del conjunto de test:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89a7fa75",
      "metadata": {
        "id": "89a7fa75"
      },
      "outputs": [],
      "source": [
        "data_request = X_test[:2].values.tolist()\n",
        "display(data_request)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4c52b73",
      "metadata": {
        "id": "b4c52b73"
      },
      "source": [
        "Finalmente, enviamos los datos para que el modelo desplegado nos de una predicción:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99dc5c90",
      "metadata": {
        "id": "99dc5c90"
      },
      "outputs": [],
      "source": [
        "r = requests.post(\"http://localhost:8001/invocations\", json={\"inputs\": data_request})\n",
        "print(r.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a73abaa8",
      "metadata": {
        "id": "a73abaa8"
      },
      "source": [
        "Como podemos ver, el API nos retorna las predicciones del modelo de una forma muy sencilla. Así mismo, `mlflow` nos permite hacer despliegues como aplicaciones web con un único comando."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4. Referencias**\n",
        "---\n",
        "\n",
        "**[1]** J. E. Camargo, J. S. Lara, E. Hernández, R. A. Superlano, and M. A. Rodríguez, \"Despliege de Modelos con MLFlow,\" in Machine Learning and Data Science Specialization, Universidad Nacional de Colombia, 2023. [Online]. Available: https://colab.research.google.com/github/mindlab-unal/MLDS6/blob/main/u4/Despliegue_de_Modelos_con_MLFlow.ipynb\n"
      ],
      "metadata": {
        "id": "0m_j0XMKcfxy"
      },
      "id": "0m_j0XMKcfxy"
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "colab": {
      "private_outputs": true,
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}